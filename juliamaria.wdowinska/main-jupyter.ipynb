{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from UDFs import TextPreprocessor\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pd.set_option('display.max_columns', None) # To display all columns in the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_jokes = pd.read_csv('jokes.csv')\n",
    "print(df_jokes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"There are no missing values.\" if not df_jokes.isnull().any().any() else \"There are missing values in the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for data types\n",
    "print(\"Data types of columns in the dataframe:\\n\" + \"\\n\".join([f\"{column}: {dtype}\" for column, dtype in df_jokes.dtypes.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of observations\n",
    "print(f\"The dataframe contains {df_jokes.shape[0]} observations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess 'text' and update the dataframe\n",
    "text_preprocessor = TextPreprocessor()\n",
    "df_jokes['processed_text'] = df_jokes['text'].apply(text_preprocessor.preprocess)\n",
    "print(df_jokes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Text length distribution for Humor vs. Not Humor\n",
    "df_jokes['text_length'] = df_jokes['processed_text'].apply(len)\n",
    "plt.hist(df_jokes[df_jokes['humor'] == True]['text_length'], bins = 30, alpha = 0.5, label = 'Humorous')\n",
    "plt.hist(df_jokes[df_jokes['humor'] == False]['text_length'], bins = 30, alpha = 0.5, label = 'Unhumorous')\n",
    "plt.legend()\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Text Length for Humorous vs. Unhumorous')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Wordcloud for Humorous and Unhumorous Texts\n",
    "plt.figure(figsize = (14, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(WordCloud(background_color = 'white').generate(\" \".join(df_jokes.processed_text[df_jokes.humor == True])))\n",
    "plt.title(\"Wordcloud for Humorous Texts\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(WordCloud(background_color = 'white').generate(\" \".join(df_jokes.processed_text[df_jokes.humor == False])))\n",
    "plt.title(\"Wordcloud for Unhumorous Texts\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data balance\n",
    "humorous_count = df_jokes.humor.sum()\n",
    "unhumorous_count = df_jokes.shape[0] - humorous_count\n",
    "print(f\"Number of humorous texts: {humorous_count}\\nNumber of unhumorous texts: {unhumorous_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'True' -> 1, 'False' -> 0\n",
    "df_jokes.humor = df_jokes.humor.astype(int)\n",
    "print(df_jokes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_jokes.processed_text.values, df_jokes.humor.values, test_size = 0.3, random_state = 42)\n",
    "\n",
    "print(f\"Size of the training set: {len(X_train)}\\nSize of the test set: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vectorizers\n",
    "count_vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Vectorize 'text' using CountVectorizer\n",
    "X_train_count_vectorized = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count_vectorized = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Vectorize 'text' using TF-IDF Vectorizer\n",
    "X_train_tfidf_vectorized = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf_vectorized = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression (LR) with Stochastic Gradient Descent (SGD) training using CountVectorizer\n",
    "lr_classifier_count_vectorized = SGDClassifier(loss = 'log_loss', max_iter = 1000)\n",
    "lr_classifier_count_vectorized.fit(X_train_count_vectorized, y_train)\n",
    "\n",
    "# Logistic regression (LR) with Stochastic Gradient Descent (SGD) training using TF-IDF Vectorizer\n",
    "lr_classifier_tfidf_vectorized = SGDClassifier(loss = 'log_loss', max_iter = 1000)\n",
    "lr_classifier_tfidf_vectorized.fit(X_train_tfidf_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes (MNB) training using CountVectorizer\n",
    "mnb_classifier_count_vectorized = MultinomialNB()\n",
    "mnb_classifier_count_vectorized.fit(X_train_count_vectorized, y_train)\n",
    "\n",
    "# Multinomial Naive Bayes (MNB) training using TF-IDF Vectorizer\n",
    "mnb_classifier_tfidf_vectorized = MultinomialNB()\n",
    "mnb_classifier_tfidf_vectorized.fit(X_train_tfidf_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for Logistic Regression with CountVectorizer\n",
    "y_pred_lr_count = lr_classifier_count_vectorized.predict(X_test_count_vectorized)\n",
    "accuracy_lr_count = accuracy_score(y_test, y_pred_lr_count)\n",
    "\n",
    "# Predictions for Logistic Regression with TF-IDF Vectorizer\n",
    "y_pred_lr_tfidf = lr_classifier_tfidf_vectorized.predict(X_test_tfidf_vectorized)\n",
    "accuracy_lr_tfidf = accuracy_score(y_test, y_pred_lr_tfidf)\n",
    "\n",
    "# Predictions for Multinomial Naive Bayes with CountVectorizer\n",
    "y_pred_mnb_count = mnb_classifier_count_vectorized.predict(X_test_count_vectorized)\n",
    "accuracy_mnb_count = accuracy_score(y_test, y_pred_mnb_count)\n",
    "\n",
    "# Predictions for Multinomial Naive Bayes with TF-IDF Vectorizer\n",
    "y_pred_mnb_tfidf = mnb_classifier_tfidf_vectorized.predict(X_test_tfidf_vectorized)\n",
    "accuracy_mnb_tfidf = accuracy_score(y_test, y_pred_mnb_tfidf)\n",
    "\n",
    "# Print the accuracies\n",
    "print(f\"Accuracy for Logistic Regression with CountVectorizer: {accuracy_lr_count:.4f}\\\n",
    "      \\nAccuracy for Logistic Regression with TF-IDF Vectorizer: {accuracy_lr_tfidf:.4f}\\\n",
    "      \\nAccuracy for Multinomial Naive Bayes with CountVectorizer: {accuracy_mnb_count:.4f}\\\n",
    "      \\nAccuracy for Multinomial Naive Bayes with TF-IDF Vectorizer: {accuracy_mnb_tfidf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dscoding-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
